{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Diabetes Detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+w9IuKCxupT7/3w/e37vL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ryan-spec/Portfolio-Projects/blob/master/Copy_of_Diabetes_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30feLLmd9IN8",
        "colab_type": "text"
      },
      "source": [
        "#**Diabetes Detection Using Machine Learning**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghDwUH9-9rHC",
        "colab_type": "text"
      },
      "source": [
        "#### The Pima people have been instrumental in giving us great insight into Diabetes by their willingness to participate in research. Their involvement has led to significant findings with reguard to the epidemeology, physiology, clinical assessement and genetics of both type2 diabetes and obesity. \n",
        "\n",
        "###This information comes the national center for biotechnology information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94CeXgD38OH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will attempt to detect whether a person has diabetes or not"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvI1VKkg_umS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jePDZouAYVV",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "09f1ae6e-ea6a-4ef0-80df-146cbd8da951"
      },
      "source": [
        "# Load the data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c977f309-983b-4b06-86c4-922805d48abf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c977f309-983b-4b06-86c4-922805d48abf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving datasets_228_482_diabetes.csv to datasets_228_482_diabetes.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9frd2hSiAkhV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "85fc0385-996e-43a8-a3a8-90a5fbc61dc5"
      },
      "source": [
        "# Store the data into a dataframe\n",
        "df = pd.read_csv('datasets_228_482_diabetes.csv')\n",
        "\n",
        "# Get the first five rows of data\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkygR6lICX0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1eb51f6b-1de5-497e-dc1e-10abfbe9a52b"
      },
      "source": [
        "# Get the shape of the data i.e rows and columns\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtMYoL5lDpnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check for duplicates and remove them \n",
        "df.drop_duplicates(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq5FJrcGD-r-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "017c5a58-1d94-4525-c4d4-fc423c54c5c1"
      },
      "source": [
        "# Get the new shape\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blHg_mzEEDSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "4381778d-eb6b-4d2d-f519-666a52b1204c"
      },
      "source": [
        "# Get the number of missing data\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                 0\n",
              "Glucose                     0\n",
              "BloodPressure               0\n",
              "SkinThickness               0\n",
              "Insulin                     0\n",
              "BMI                         0\n",
              "DiabetesPedigreeFunction    0\n",
              "Age                         0\n",
              "Outcome                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62mKIbv8EM6Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "3ea0f474-0349-44d9-d879-46290c549f60"
      },
      "source": [
        "# Convert the data into an array\n",
        "dataset = df.values\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9paNrqebEazT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get all of the rows from the first eight columns of the dataset\n",
        "X = dataset[:, 0:8] \n",
        "y = dataset[:, 8]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWcHI7StE6sx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "43eeb981-4eec-4ba9-8376-2dbb4ba10b94"
      },
      "source": [
        "# Process the data\n",
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agE70LJzGGsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data inot 80% and 20% testing \n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.2, random_state=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kWb4_SUGivE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build our model \n",
        "model = Sequential([\n",
        "    Dense(12, activation='relu', input_shape =(8,)),\n",
        "    Dense(15, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtVghtPVHJaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='sgd',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsYp_63mHywb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "927bc7a8-3daa-4721-8f8a-721cd2eae44a"
      },
      "source": [
        "# Train the model \n",
        "hist = model.fit(X_train, y_train, batch_size=42, epochs=1000, validation_split=0.2 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6719 - accuracy: 0.6477 - val_loss: 0.6709 - val_accuracy: 0.6504\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.6477 - val_loss: 0.6674 - val_accuracy: 0.6504\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.6477 - val_loss: 0.6646 - val_accuracy: 0.6504\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.6477 - val_loss: 0.6623 - val_accuracy: 0.6504\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.6477 - val_loss: 0.6604 - val_accuracy: 0.6504\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.6477 - val_loss: 0.6591 - val_accuracy: 0.6504\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6477 - val_loss: 0.6578 - val_accuracy: 0.6504\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.6477 - val_loss: 0.6567 - val_accuracy: 0.6504\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.6477 - val_loss: 0.6557 - val_accuracy: 0.6504\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.6477 - val_loss: 0.6549 - val_accuracy: 0.6504\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.6477 - val_loss: 0.6541 - val_accuracy: 0.6504\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6477 - val_loss: 0.6534 - val_accuracy: 0.6504\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.6477 - val_loss: 0.6527 - val_accuracy: 0.6504\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6523 - accuracy: 0.6477 - val_loss: 0.6521 - val_accuracy: 0.6504\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.6477 - val_loss: 0.6515 - val_accuracy: 0.6504\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.6477 - val_loss: 0.6509 - val_accuracy: 0.6504\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.6477 - val_loss: 0.6503 - val_accuracy: 0.6504\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.6477 - val_loss: 0.6497 - val_accuracy: 0.6504\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.6477 - val_loss: 0.6492 - val_accuracy: 0.6504\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.6477 - val_loss: 0.6486 - val_accuracy: 0.6504\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.6477 - val_loss: 0.6481 - val_accuracy: 0.6504\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.6477 - val_loss: 0.6475 - val_accuracy: 0.6504\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.6477 - val_loss: 0.6470 - val_accuracy: 0.6504\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.6477 - val_loss: 0.6464 - val_accuracy: 0.6504\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6477 - val_loss: 0.6458 - val_accuracy: 0.6504\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.6477 - val_loss: 0.6452 - val_accuracy: 0.6504\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.6477 - val_loss: 0.6446 - val_accuracy: 0.6504\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6477 - val_loss: 0.6440 - val_accuracy: 0.6504\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.6477 - val_loss: 0.6435 - val_accuracy: 0.6504\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.6477 - val_loss: 0.6429 - val_accuracy: 0.6504\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.6477 - val_loss: 0.6423 - val_accuracy: 0.6504\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.6477 - val_loss: 0.6418 - val_accuracy: 0.6504\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6477 - val_loss: 0.6412 - val_accuracy: 0.6504\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.6477 - val_loss: 0.6406 - val_accuracy: 0.6504\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.6477 - val_loss: 0.6400 - val_accuracy: 0.6504\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6477 - val_loss: 0.6394 - val_accuracy: 0.6504\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.6477 - val_loss: 0.6388 - val_accuracy: 0.6504\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.6477 - val_loss: 0.6382 - val_accuracy: 0.6504\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.6477 - val_loss: 0.6377 - val_accuracy: 0.6504\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.6477 - val_loss: 0.6371 - val_accuracy: 0.6504\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.6477 - val_loss: 0.6365 - val_accuracy: 0.6504\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.6477 - val_loss: 0.6359 - val_accuracy: 0.6504\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.6477 - val_loss: 0.6354 - val_accuracy: 0.6504\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.6477 - val_loss: 0.6347 - val_accuracy: 0.6504\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6477 - val_loss: 0.6342 - val_accuracy: 0.6504\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.6477 - val_loss: 0.6336 - val_accuracy: 0.6504\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.6477 - val_loss: 0.6330 - val_accuracy: 0.6504\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.6477 - val_loss: 0.6325 - val_accuracy: 0.6504\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.6477 - val_loss: 0.6319 - val_accuracy: 0.6504\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.6477 - val_loss: 0.6314 - val_accuracy: 0.6504\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.6477 - val_loss: 0.6309 - val_accuracy: 0.6504\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.6477 - val_loss: 0.6304 - val_accuracy: 0.6504\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6477 - val_loss: 0.6298 - val_accuracy: 0.6504\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.6477 - val_loss: 0.6292 - val_accuracy: 0.6504\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6477 - val_loss: 0.6287 - val_accuracy: 0.6504\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6477 - val_loss: 0.6280 - val_accuracy: 0.6504\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.6477 - val_loss: 0.6274 - val_accuracy: 0.6504\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.6477 - val_loss: 0.6269 - val_accuracy: 0.6504\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6477 - val_loss: 0.6263 - val_accuracy: 0.6504\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.6477 - val_loss: 0.6257 - val_accuracy: 0.6504\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.6477 - val_loss: 0.6251 - val_accuracy: 0.6504\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.6477 - val_loss: 0.6245 - val_accuracy: 0.6504\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.6477 - val_loss: 0.6240 - val_accuracy: 0.6504\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.6477 - val_loss: 0.6234 - val_accuracy: 0.6504\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6221 - accuracy: 0.6477 - val_loss: 0.6228 - val_accuracy: 0.6504\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.6477 - val_loss: 0.6222 - val_accuracy: 0.6504\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.6477 - val_loss: 0.6216 - val_accuracy: 0.6504\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.6477 - val_loss: 0.6209 - val_accuracy: 0.6504\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.6477 - val_loss: 0.6203 - val_accuracy: 0.6504\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.6477 - val_loss: 0.6198 - val_accuracy: 0.6504\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.6477 - val_loss: 0.6192 - val_accuracy: 0.6504\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6175 - accuracy: 0.6477 - val_loss: 0.6186 - val_accuracy: 0.6504\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.6477 - val_loss: 0.6180 - val_accuracy: 0.6504\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.6477 - val_loss: 0.6173 - val_accuracy: 0.6504\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.6477 - val_loss: 0.6167 - val_accuracy: 0.6504\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.6477 - val_loss: 0.6161 - val_accuracy: 0.6504\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6477 - val_loss: 0.6155 - val_accuracy: 0.6504\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6132 - accuracy: 0.6497 - val_loss: 0.6149 - val_accuracy: 0.6504\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.6517 - val_loss: 0.6142 - val_accuracy: 0.6504\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.6517 - val_loss: 0.6136 - val_accuracy: 0.6504\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.6517 - val_loss: 0.6130 - val_accuracy: 0.6504\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.6517 - val_loss: 0.6124 - val_accuracy: 0.6504\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6517 - val_loss: 0.6118 - val_accuracy: 0.6585\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.6517 - val_loss: 0.6111 - val_accuracy: 0.6585\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.6517 - val_loss: 0.6105 - val_accuracy: 0.6585\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6071 - accuracy: 0.6517 - val_loss: 0.6099 - val_accuracy: 0.6585\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.6517 - val_loss: 0.6092 - val_accuracy: 0.6585\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.6517 - val_loss: 0.6087 - val_accuracy: 0.6585\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.6538 - val_loss: 0.6079 - val_accuracy: 0.6585\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.6558 - val_loss: 0.6073 - val_accuracy: 0.6585\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.6538 - val_loss: 0.6067 - val_accuracy: 0.6667\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.6578 - val_loss: 0.6060 - val_accuracy: 0.6667\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.6578 - val_loss: 0.6053 - val_accuracy: 0.6667\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.6578 - val_loss: 0.6047 - val_accuracy: 0.6667\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.6578 - val_loss: 0.6041 - val_accuracy: 0.6667\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.6619 - val_loss: 0.6033 - val_accuracy: 0.6667\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.6599 - val_loss: 0.6026 - val_accuracy: 0.6667\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.6599 - val_loss: 0.6019 - val_accuracy: 0.6667\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.6599 - val_loss: 0.6012 - val_accuracy: 0.6667\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.6701 - val_loss: 0.6004 - val_accuracy: 0.6667\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.6619 - val_loss: 0.5998 - val_accuracy: 0.6748\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.6680 - val_loss: 0.5990 - val_accuracy: 0.6748\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5933 - accuracy: 0.6680 - val_loss: 0.5983 - val_accuracy: 0.6829\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.6680 - val_loss: 0.5975 - val_accuracy: 0.6829\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.6680 - val_loss: 0.5968 - val_accuracy: 0.6829\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.6701 - val_loss: 0.5960 - val_accuracy: 0.6829\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.6741 - val_loss: 0.5953 - val_accuracy: 0.6748\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.6721 - val_loss: 0.5945 - val_accuracy: 0.6748\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.6721 - val_loss: 0.5937 - val_accuracy: 0.6748\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.6701 - val_loss: 0.5931 - val_accuracy: 0.6748\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.6721 - val_loss: 0.5923 - val_accuracy: 0.6748\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.6741 - val_loss: 0.5915 - val_accuracy: 0.6748\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.6762 - val_loss: 0.5908 - val_accuracy: 0.6748\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.6782 - val_loss: 0.5900 - val_accuracy: 0.6748\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6782 - val_loss: 0.5892 - val_accuracy: 0.6829\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.6782 - val_loss: 0.5885 - val_accuracy: 0.6748\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.6802 - val_loss: 0.5878 - val_accuracy: 0.6829\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.6843 - val_loss: 0.5869 - val_accuracy: 0.6829\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.6782 - val_loss: 0.5862 - val_accuracy: 0.6911\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.6823 - val_loss: 0.5855 - val_accuracy: 0.6911\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.6925 - val_loss: 0.5847 - val_accuracy: 0.6911\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.6925 - val_loss: 0.5839 - val_accuracy: 0.6911\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.6884 - val_loss: 0.5832 - val_accuracy: 0.6911\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.6884 - val_loss: 0.5825 - val_accuracy: 0.6911\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.6884 - val_loss: 0.5818 - val_accuracy: 0.6911\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.6904 - val_loss: 0.5810 - val_accuracy: 0.6911\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.6925 - val_loss: 0.5803 - val_accuracy: 0.6911\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.6904 - val_loss: 0.5796 - val_accuracy: 0.6911\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.6965 - val_loss: 0.5789 - val_accuracy: 0.6992\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.7026 - val_loss: 0.5781 - val_accuracy: 0.6992\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.7006 - val_loss: 0.5774 - val_accuracy: 0.7073\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7067 - val_loss: 0.5766 - val_accuracy: 0.7073\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7088 - val_loss: 0.5758 - val_accuracy: 0.7073\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7088 - val_loss: 0.5751 - val_accuracy: 0.6992\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7108 - val_loss: 0.5744 - val_accuracy: 0.6992\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7128 - val_loss: 0.5737 - val_accuracy: 0.7073\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7088 - val_loss: 0.5730 - val_accuracy: 0.7073\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7128 - val_loss: 0.5723 - val_accuracy: 0.7073\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7128 - val_loss: 0.5716 - val_accuracy: 0.7073\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5593 - accuracy: 0.7128 - val_loss: 0.5709 - val_accuracy: 0.7073\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.7210 - val_loss: 0.5700 - val_accuracy: 0.7073\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7169 - val_loss: 0.5694 - val_accuracy: 0.7073\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.7230 - val_loss: 0.5686 - val_accuracy: 0.7073\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7251 - val_loss: 0.5678 - val_accuracy: 0.7073\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.7230 - val_loss: 0.5671 - val_accuracy: 0.7073\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7291 - val_loss: 0.5664 - val_accuracy: 0.7073\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7271 - val_loss: 0.5657 - val_accuracy: 0.7073\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7291 - val_loss: 0.5649 - val_accuracy: 0.7073\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7312 - val_loss: 0.5642 - val_accuracy: 0.6992\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7312 - val_loss: 0.5635 - val_accuracy: 0.6992\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7312 - val_loss: 0.5628 - val_accuracy: 0.6992\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7271 - val_loss: 0.5621 - val_accuracy: 0.6992\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7291 - val_loss: 0.5614 - val_accuracy: 0.6992\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7291 - val_loss: 0.5607 - val_accuracy: 0.6911\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7312 - val_loss: 0.5601 - val_accuracy: 0.6992\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7271 - val_loss: 0.5594 - val_accuracy: 0.7073\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7251 - val_loss: 0.5587 - val_accuracy: 0.7073\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.7251 - val_loss: 0.5580 - val_accuracy: 0.7154\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.7251 - val_loss: 0.5573 - val_accuracy: 0.7154\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7251 - val_loss: 0.5566 - val_accuracy: 0.7154\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7251 - val_loss: 0.5560 - val_accuracy: 0.7154\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7291 - val_loss: 0.5554 - val_accuracy: 0.7154\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7251 - val_loss: 0.5547 - val_accuracy: 0.7154\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7291 - val_loss: 0.5541 - val_accuracy: 0.6992\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7312 - val_loss: 0.5535 - val_accuracy: 0.7073\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7312 - val_loss: 0.5529 - val_accuracy: 0.6992\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7271 - val_loss: 0.5524 - val_accuracy: 0.6911\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7332 - val_loss: 0.5518 - val_accuracy: 0.6911\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7332 - val_loss: 0.5511 - val_accuracy: 0.6911\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7332 - val_loss: 0.5505 - val_accuracy: 0.6911\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7413 - val_loss: 0.5498 - val_accuracy: 0.6911\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7312 - val_loss: 0.5492 - val_accuracy: 0.6911\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7393 - val_loss: 0.5487 - val_accuracy: 0.6992\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7373 - val_loss: 0.5481 - val_accuracy: 0.6992\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7312 - val_loss: 0.5476 - val_accuracy: 0.7154\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7373 - val_loss: 0.5470 - val_accuracy: 0.7154\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7352 - val_loss: 0.5465 - val_accuracy: 0.7154\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7393 - val_loss: 0.5460 - val_accuracy: 0.7154\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7413 - val_loss: 0.5455 - val_accuracy: 0.7154\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7475 - val_loss: 0.5449 - val_accuracy: 0.7154\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7352 - val_loss: 0.5445 - val_accuracy: 0.7236\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7454 - val_loss: 0.5439 - val_accuracy: 0.7154\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7495 - val_loss: 0.5434 - val_accuracy: 0.7154\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7515 - val_loss: 0.5428 - val_accuracy: 0.7154\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7434 - val_loss: 0.5424 - val_accuracy: 0.7154\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7515 - val_loss: 0.5419 - val_accuracy: 0.7154\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7454 - val_loss: 0.5414 - val_accuracy: 0.7154\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7475 - val_loss: 0.5410 - val_accuracy: 0.7154\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7515 - val_loss: 0.5406 - val_accuracy: 0.7236\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7536 - val_loss: 0.5400 - val_accuracy: 0.7154\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7597 - val_loss: 0.5395 - val_accuracy: 0.7154\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7556 - val_loss: 0.5391 - val_accuracy: 0.7154\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7515 - val_loss: 0.5386 - val_accuracy: 0.7073\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7536 - val_loss: 0.5382 - val_accuracy: 0.7154\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7515 - val_loss: 0.5378 - val_accuracy: 0.7236\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7536 - val_loss: 0.5374 - val_accuracy: 0.7236\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7495 - val_loss: 0.5372 - val_accuracy: 0.7236\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7576 - val_loss: 0.5366 - val_accuracy: 0.7154\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7597 - val_loss: 0.5362 - val_accuracy: 0.7154\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7556 - val_loss: 0.5358 - val_accuracy: 0.7236\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7515 - val_loss: 0.5354 - val_accuracy: 0.7154\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7556 - val_loss: 0.5355 - val_accuracy: 0.7236\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7576 - val_loss: 0.5347 - val_accuracy: 0.7236\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7536 - val_loss: 0.5343 - val_accuracy: 0.7236\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7597 - val_loss: 0.5339 - val_accuracy: 0.7236\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7556 - val_loss: 0.5336 - val_accuracy: 0.7236\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7597 - val_loss: 0.5332 - val_accuracy: 0.7236\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7556 - val_loss: 0.5330 - val_accuracy: 0.7236\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7576 - val_loss: 0.5326 - val_accuracy: 0.7236\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7536 - val_loss: 0.5323 - val_accuracy: 0.7236\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7576 - val_loss: 0.5321 - val_accuracy: 0.7236\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7597 - val_loss: 0.5316 - val_accuracy: 0.7236\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7597 - val_loss: 0.5313 - val_accuracy: 0.7236\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7597 - val_loss: 0.5311 - val_accuracy: 0.7236\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7556 - val_loss: 0.5309 - val_accuracy: 0.7236\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7556 - val_loss: 0.5305 - val_accuracy: 0.7236\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7576 - val_loss: 0.5303 - val_accuracy: 0.7236\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.7617 - val_loss: 0.5302 - val_accuracy: 0.7236\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7556 - val_loss: 0.5295 - val_accuracy: 0.7236\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7576 - val_loss: 0.5292 - val_accuracy: 0.7236\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7597 - val_loss: 0.5289 - val_accuracy: 0.7236\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7556 - val_loss: 0.5287 - val_accuracy: 0.7236\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7597 - val_loss: 0.5284 - val_accuracy: 0.7236\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7576 - val_loss: 0.5281 - val_accuracy: 0.7236\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.7576 - val_loss: 0.5279 - val_accuracy: 0.7236\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7576 - val_loss: 0.5277 - val_accuracy: 0.7236\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7576 - val_loss: 0.5273 - val_accuracy: 0.7236\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7617 - val_loss: 0.5271 - val_accuracy: 0.7236\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.7536 - val_loss: 0.5269 - val_accuracy: 0.7236\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7576 - val_loss: 0.5266 - val_accuracy: 0.7236\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7597 - val_loss: 0.5264 - val_accuracy: 0.7317\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.7536 - val_loss: 0.5261 - val_accuracy: 0.7236\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7536 - val_loss: 0.5259 - val_accuracy: 0.7236\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7576 - val_loss: 0.5257 - val_accuracy: 0.7317\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7536 - val_loss: 0.5254 - val_accuracy: 0.7317\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7556 - val_loss: 0.5251 - val_accuracy: 0.7398\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7576 - val_loss: 0.5251 - val_accuracy: 0.7317\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7475 - val_loss: 0.5246 - val_accuracy: 0.7317\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7576 - val_loss: 0.5243 - val_accuracy: 0.7398\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7576 - val_loss: 0.5241 - val_accuracy: 0.7398\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7515 - val_loss: 0.5239 - val_accuracy: 0.7398\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7515 - val_loss: 0.5236 - val_accuracy: 0.7398\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7495 - val_loss: 0.5234 - val_accuracy: 0.7398\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7536 - val_loss: 0.5233 - val_accuracy: 0.7317\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7495 - val_loss: 0.5231 - val_accuracy: 0.7398\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7515 - val_loss: 0.5229 - val_accuracy: 0.7398\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7576 - val_loss: 0.5226 - val_accuracy: 0.7398\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7597 - val_loss: 0.5223 - val_accuracy: 0.7398\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7536 - val_loss: 0.5223 - val_accuracy: 0.7317\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7536 - val_loss: 0.5219 - val_accuracy: 0.7317\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7576 - val_loss: 0.5217 - val_accuracy: 0.7398\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7536 - val_loss: 0.5215 - val_accuracy: 0.7317\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7536 - val_loss: 0.5212 - val_accuracy: 0.7398\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7515 - val_loss: 0.5211 - val_accuracy: 0.7398\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7536 - val_loss: 0.5209 - val_accuracy: 0.7398\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7475 - val_loss: 0.5205 - val_accuracy: 0.7398\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7536 - val_loss: 0.5206 - val_accuracy: 0.7317\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7576 - val_loss: 0.5200 - val_accuracy: 0.7317\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7515 - val_loss: 0.5199 - val_accuracy: 0.7317\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7515 - val_loss: 0.5197 - val_accuracy: 0.7317\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7515 - val_loss: 0.5193 - val_accuracy: 0.7317\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7597 - val_loss: 0.5190 - val_accuracy: 0.7317\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7536 - val_loss: 0.5188 - val_accuracy: 0.7398\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7536 - val_loss: 0.5185 - val_accuracy: 0.7317\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7597 - val_loss: 0.5184 - val_accuracy: 0.7398\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7556 - val_loss: 0.5182 - val_accuracy: 0.7398\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7556 - val_loss: 0.5178 - val_accuracy: 0.7317\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7515 - val_loss: 0.5176 - val_accuracy: 0.7317\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7739 - val_loss: 0.5172 - val_accuracy: 0.7317\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7637 - val_loss: 0.5170 - val_accuracy: 0.7398\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7597 - val_loss: 0.5170 - val_accuracy: 0.7317\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7597 - val_loss: 0.5167 - val_accuracy: 0.7317\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7597 - val_loss: 0.5164 - val_accuracy: 0.7317\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7597 - val_loss: 0.5162 - val_accuracy: 0.7398\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7617 - val_loss: 0.5161 - val_accuracy: 0.7317\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7658 - val_loss: 0.5159 - val_accuracy: 0.7398\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7576 - val_loss: 0.5158 - val_accuracy: 0.7398\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7637 - val_loss: 0.5155 - val_accuracy: 0.7398\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7658 - val_loss: 0.5154 - val_accuracy: 0.7398\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7658 - val_loss: 0.5153 - val_accuracy: 0.7398\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7556 - val_loss: 0.5148 - val_accuracy: 0.7398\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7617 - val_loss: 0.5147 - val_accuracy: 0.7398\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7637 - val_loss: 0.5146 - val_accuracy: 0.7398\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7597 - val_loss: 0.5143 - val_accuracy: 0.7317\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7637 - val_loss: 0.5143 - val_accuracy: 0.7398\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7617 - val_loss: 0.5142 - val_accuracy: 0.7398\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7678 - val_loss: 0.5144 - val_accuracy: 0.7398\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7637 - val_loss: 0.5138 - val_accuracy: 0.7398\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7678 - val_loss: 0.5136 - val_accuracy: 0.7398\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7576 - val_loss: 0.5136 - val_accuracy: 0.7398\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7658 - val_loss: 0.5134 - val_accuracy: 0.7398\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7699 - val_loss: 0.5138 - val_accuracy: 0.7398\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7576 - val_loss: 0.5131 - val_accuracy: 0.7398\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7739 - val_loss: 0.5130 - val_accuracy: 0.7398\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7719 - val_loss: 0.5130 - val_accuracy: 0.7317\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7699 - val_loss: 0.5129 - val_accuracy: 0.7398\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7678 - val_loss: 0.5127 - val_accuracy: 0.7398\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7576 - val_loss: 0.5127 - val_accuracy: 0.7398\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7678 - val_loss: 0.5130 - val_accuracy: 0.7398\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7637 - val_loss: 0.5131 - val_accuracy: 0.7317\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7658 - val_loss: 0.5127 - val_accuracy: 0.7398\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7617 - val_loss: 0.5123 - val_accuracy: 0.7398\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7617 - val_loss: 0.5120 - val_accuracy: 0.7398\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7699 - val_loss: 0.5120 - val_accuracy: 0.7480\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7658 - val_loss: 0.5124 - val_accuracy: 0.7398\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7658 - val_loss: 0.5116 - val_accuracy: 0.7398\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7637 - val_loss: 0.5115 - val_accuracy: 0.7398\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7699 - val_loss: 0.5114 - val_accuracy: 0.7398\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7597 - val_loss: 0.5112 - val_accuracy: 0.7398\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7658 - val_loss: 0.5112 - val_accuracy: 0.7398\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7719 - val_loss: 0.5113 - val_accuracy: 0.7480\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7658 - val_loss: 0.5110 - val_accuracy: 0.7317\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7658 - val_loss: 0.5109 - val_accuracy: 0.7398\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7678 - val_loss: 0.5109 - val_accuracy: 0.7398\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7678 - val_loss: 0.5109 - val_accuracy: 0.7398\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7678 - val_loss: 0.5108 - val_accuracy: 0.7398\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7699 - val_loss: 0.5106 - val_accuracy: 0.7398\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7658 - val_loss: 0.5105 - val_accuracy: 0.7398\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7699 - val_loss: 0.5106 - val_accuracy: 0.7480\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7678 - val_loss: 0.5109 - val_accuracy: 0.7317\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7658 - val_loss: 0.5104 - val_accuracy: 0.7480\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7658 - val_loss: 0.5110 - val_accuracy: 0.7317\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7617 - val_loss: 0.5104 - val_accuracy: 0.7480\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7719 - val_loss: 0.5106 - val_accuracy: 0.7317\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7658 - val_loss: 0.5103 - val_accuracy: 0.7480\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7760 - val_loss: 0.5116 - val_accuracy: 0.7317\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7637 - val_loss: 0.5108 - val_accuracy: 0.7317\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7699 - val_loss: 0.5098 - val_accuracy: 0.7480\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7699 - val_loss: 0.5097 - val_accuracy: 0.7480\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7678 - val_loss: 0.5098 - val_accuracy: 0.7561\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7699 - val_loss: 0.5098 - val_accuracy: 0.7480\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7658 - val_loss: 0.5099 - val_accuracy: 0.7561\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7637 - val_loss: 0.5098 - val_accuracy: 0.7561\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7658 - val_loss: 0.5095 - val_accuracy: 0.7398\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.5100 - val_accuracy: 0.7317\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7719 - val_loss: 0.5102 - val_accuracy: 0.7317\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7658 - val_loss: 0.5094 - val_accuracy: 0.7480\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7800 - val_loss: 0.5091 - val_accuracy: 0.7480\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7699 - val_loss: 0.5091 - val_accuracy: 0.7480\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7719 - val_loss: 0.5092 - val_accuracy: 0.7480\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7739 - val_loss: 0.5094 - val_accuracy: 0.7398\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7678 - val_loss: 0.5089 - val_accuracy: 0.7561\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7678 - val_loss: 0.5089 - val_accuracy: 0.7480\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7739 - val_loss: 0.5091 - val_accuracy: 0.7480\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7739 - val_loss: 0.5090 - val_accuracy: 0.7480\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7800 - val_loss: 0.5088 - val_accuracy: 0.7480\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7800 - val_loss: 0.5088 - val_accuracy: 0.7480\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7719 - val_loss: 0.5088 - val_accuracy: 0.7561\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7739 - val_loss: 0.5087 - val_accuracy: 0.7480\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.5100 - val_accuracy: 0.7317\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7739 - val_loss: 0.5086 - val_accuracy: 0.7480\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7739 - val_loss: 0.5086 - val_accuracy: 0.7398\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7800 - val_loss: 0.5087 - val_accuracy: 0.7480\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7800 - val_loss: 0.5090 - val_accuracy: 0.7480\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7780 - val_loss: 0.5085 - val_accuracy: 0.7561\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7800 - val_loss: 0.5085 - val_accuracy: 0.7480\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7780 - val_loss: 0.5084 - val_accuracy: 0.7480\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7841 - val_loss: 0.5086 - val_accuracy: 0.7480\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7780 - val_loss: 0.5086 - val_accuracy: 0.7480\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7699 - val_loss: 0.5081 - val_accuracy: 0.7480\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7780 - val_loss: 0.5081 - val_accuracy: 0.7480\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7780 - val_loss: 0.5080 - val_accuracy: 0.7398\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7821 - val_loss: 0.5082 - val_accuracy: 0.7480\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7780 - val_loss: 0.5089 - val_accuracy: 0.7480\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7800 - val_loss: 0.5083 - val_accuracy: 0.7480\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7821 - val_loss: 0.5080 - val_accuracy: 0.7480\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7800 - val_loss: 0.5081 - val_accuracy: 0.7480\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7780 - val_loss: 0.5080 - val_accuracy: 0.7561\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7862 - val_loss: 0.5080 - val_accuracy: 0.7480\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7821 - val_loss: 0.5080 - val_accuracy: 0.7480\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7882 - val_loss: 0.5081 - val_accuracy: 0.7480\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7480\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7760 - val_loss: 0.5080 - val_accuracy: 0.7398\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7760 - val_loss: 0.5080 - val_accuracy: 0.7561\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7841 - val_loss: 0.5081 - val_accuracy: 0.7480\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7800 - val_loss: 0.5082 - val_accuracy: 0.7480\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7800 - val_loss: 0.5079 - val_accuracy: 0.7398\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7841 - val_loss: 0.5086 - val_accuracy: 0.7561\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7739 - val_loss: 0.5079 - val_accuracy: 0.7398\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7800 - val_loss: 0.5085 - val_accuracy: 0.7561\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7841 - val_loss: 0.5087 - val_accuracy: 0.7480\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7780 - val_loss: 0.5082 - val_accuracy: 0.7480\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7480\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7821 - val_loss: 0.5083 - val_accuracy: 0.7561\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7561\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7821 - val_loss: 0.5080 - val_accuracy: 0.7561\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7780 - val_loss: 0.5078 - val_accuracy: 0.7398\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7862 - val_loss: 0.5082 - val_accuracy: 0.7561\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7902 - val_loss: 0.5084 - val_accuracy: 0.7561\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7780 - val_loss: 0.5078 - val_accuracy: 0.7480\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7821 - val_loss: 0.5085 - val_accuracy: 0.7561\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7821 - val_loss: 0.5081 - val_accuracy: 0.7561\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7862 - val_loss: 0.5082 - val_accuracy: 0.7561\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7780 - val_loss: 0.5078 - val_accuracy: 0.7561\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7841 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7780 - val_loss: 0.5077 - val_accuracy: 0.7561\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7902 - val_loss: 0.5087 - val_accuracy: 0.7480\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7862 - val_loss: 0.5090 - val_accuracy: 0.7480\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7480\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7800 - val_loss: 0.5077 - val_accuracy: 0.7561\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7480\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7821 - val_loss: 0.5082 - val_accuracy: 0.7561\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7821 - val_loss: 0.5080 - val_accuracy: 0.7561\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7862 - val_loss: 0.5094 - val_accuracy: 0.7480\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7760 - val_loss: 0.5077 - val_accuracy: 0.7561\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7862 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7902 - val_loss: 0.5083 - val_accuracy: 0.7561\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7780 - val_loss: 0.5080 - val_accuracy: 0.7561\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7862 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7821 - val_loss: 0.5078 - val_accuracy: 0.7642\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7862 - val_loss: 0.5082 - val_accuracy: 0.7561\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7862 - val_loss: 0.5081 - val_accuracy: 0.7561\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7821 - val_loss: 0.5081 - val_accuracy: 0.7561\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7821 - val_loss: 0.5081 - val_accuracy: 0.7561\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7923 - val_loss: 0.5086 - val_accuracy: 0.7561\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7902 - val_loss: 0.5087 - val_accuracy: 0.7561\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7902 - val_loss: 0.5090 - val_accuracy: 0.7480\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7821 - val_loss: 0.5086 - val_accuracy: 0.7561\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7821 - val_loss: 0.5078 - val_accuracy: 0.7561\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7561\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7943 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7862 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7780 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7862 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7902 - val_loss: 0.5085 - val_accuracy: 0.7561\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7882 - val_loss: 0.5089 - val_accuracy: 0.7480\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7862 - val_loss: 0.5091 - val_accuracy: 0.7480\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7739 - val_loss: 0.5082 - val_accuracy: 0.7561\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7561\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7800 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7841 - val_loss: 0.5081 - val_accuracy: 0.7561\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7862 - val_loss: 0.5080 - val_accuracy: 0.7561\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7841 - val_loss: 0.5082 - val_accuracy: 0.7561\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7882 - val_loss: 0.5081 - val_accuracy: 0.7561\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7841 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7561\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7561\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7821 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7800 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7841 - val_loss: 0.5085 - val_accuracy: 0.7642\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7862 - val_loss: 0.5080 - val_accuracy: 0.7561\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7862 - val_loss: 0.5081 - val_accuracy: 0.7561\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7862 - val_loss: 0.5080 - val_accuracy: 0.7561\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7862 - val_loss: 0.5081 - val_accuracy: 0.7561\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7841 - val_loss: 0.5077 - val_accuracy: 0.7642\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7724\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7902 - val_loss: 0.5077 - val_accuracy: 0.7561\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7862 - val_loss: 0.5078 - val_accuracy: 0.7561\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7841 - val_loss: 0.5076 - val_accuracy: 0.7642\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7841 - val_loss: 0.5076 - val_accuracy: 0.7642\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7561\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7800 - val_loss: 0.5086 - val_accuracy: 0.7561\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7780 - val_loss: 0.5075 - val_accuracy: 0.7642\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7841 - val_loss: 0.5078 - val_accuracy: 0.7561\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7561\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7642\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7841 - val_loss: 0.5080 - val_accuracy: 0.7561\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7821 - val_loss: 0.5077 - val_accuracy: 0.7561\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7561\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7724\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7561\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7923 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7841 - val_loss: 0.5074 - val_accuracy: 0.7561\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7841 - val_loss: 0.5071 - val_accuracy: 0.7724\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7841 - val_loss: 0.5075 - val_accuracy: 0.7561\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7800 - val_loss: 0.5074 - val_accuracy: 0.7561\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7862 - val_loss: 0.5070 - val_accuracy: 0.7724\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7800 - val_loss: 0.5071 - val_accuracy: 0.7805\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7642\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7862 - val_loss: 0.5071 - val_accuracy: 0.7642\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7561\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7800 - val_loss: 0.5074 - val_accuracy: 0.7561\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7841 - val_loss: 0.5075 - val_accuracy: 0.7561\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7821 - val_loss: 0.5070 - val_accuracy: 0.7642\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7841 - val_loss: 0.5069 - val_accuracy: 0.7724\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7902 - val_loss: 0.5069 - val_accuracy: 0.7724\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7882 - val_loss: 0.5068 - val_accuracy: 0.7805\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7862 - val_loss: 0.5071 - val_accuracy: 0.7642\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7862 - val_loss: 0.5076 - val_accuracy: 0.7642\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7902 - val_loss: 0.5070 - val_accuracy: 0.7642\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7862 - val_loss: 0.5077 - val_accuracy: 0.7561\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7841 - val_loss: 0.5069 - val_accuracy: 0.7724\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7862 - val_loss: 0.5068 - val_accuracy: 0.7805\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7923 - val_loss: 0.5067 - val_accuracy: 0.7805\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7841 - val_loss: 0.5069 - val_accuracy: 0.7642\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7841 - val_loss: 0.5070 - val_accuracy: 0.7642\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7642\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7841 - val_loss: 0.5078 - val_accuracy: 0.7642\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7841 - val_loss: 0.5073 - val_accuracy: 0.7561\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7642\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7841 - val_loss: 0.5067 - val_accuracy: 0.7724\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7862 - val_loss: 0.5074 - val_accuracy: 0.7642\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7862 - val_loss: 0.5069 - val_accuracy: 0.7642\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7862 - val_loss: 0.5067 - val_accuracy: 0.7724\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7902 - val_loss: 0.5086 - val_accuracy: 0.7642\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7821 - val_loss: 0.5081 - val_accuracy: 0.7642\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7821 - val_loss: 0.5069 - val_accuracy: 0.7805\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7821 - val_loss: 0.5068 - val_accuracy: 0.7805\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7862 - val_loss: 0.5077 - val_accuracy: 0.7642\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7841 - val_loss: 0.5070 - val_accuracy: 0.7642\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7821 - val_loss: 0.5076 - val_accuracy: 0.7642\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7642\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7882 - val_loss: 0.5070 - val_accuracy: 0.7805\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7862 - val_loss: 0.5070 - val_accuracy: 0.7724\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7862 - val_loss: 0.5076 - val_accuracy: 0.7561\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7841 - val_loss: 0.5075 - val_accuracy: 0.7561\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7821 - val_loss: 0.5074 - val_accuracy: 0.7561\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7800 - val_loss: 0.5070 - val_accuracy: 0.7642\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7642\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7862 - val_loss: 0.5086 - val_accuracy: 0.7642\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7800 - val_loss: 0.5071 - val_accuracy: 0.7805\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7805\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7902 - val_loss: 0.5072 - val_accuracy: 0.7805\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7902 - val_loss: 0.5076 - val_accuracy: 0.7561\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7923 - val_loss: 0.5078 - val_accuracy: 0.7561\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7841 - val_loss: 0.5078 - val_accuracy: 0.7561\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7841 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7862 - val_loss: 0.5087 - val_accuracy: 0.7642\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7841 - val_loss: 0.5077 - val_accuracy: 0.7561\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7724\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7902 - val_loss: 0.5076 - val_accuracy: 0.7724\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7923 - val_loss: 0.5078 - val_accuracy: 0.7561\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7902 - val_loss: 0.5085 - val_accuracy: 0.7642\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7862 - val_loss: 0.5079 - val_accuracy: 0.7642\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7724\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.5088 - val_accuracy: 0.7642\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7642\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7923 - val_loss: 0.5086 - val_accuracy: 0.7642\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7862 - val_loss: 0.5080 - val_accuracy: 0.7724\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7862 - val_loss: 0.5079 - val_accuracy: 0.7805\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7724\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7902 - val_loss: 0.5088 - val_accuracy: 0.7642\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7862 - val_loss: 0.5081 - val_accuracy: 0.7724\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7923 - val_loss: 0.5080 - val_accuracy: 0.7805\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7923 - val_loss: 0.5086 - val_accuracy: 0.7642\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7902 - val_loss: 0.5079 - val_accuracy: 0.7805\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7862 - val_loss: 0.5080 - val_accuracy: 0.7642\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7724\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7943 - val_loss: 0.5078 - val_accuracy: 0.7724\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7841 - val_loss: 0.5087 - val_accuracy: 0.7642\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7902 - val_loss: 0.5081 - val_accuracy: 0.7724\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7902 - val_loss: 0.5085 - val_accuracy: 0.7642\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7902 - val_loss: 0.5084 - val_accuracy: 0.7642\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7902 - val_loss: 0.5077 - val_accuracy: 0.7724\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7902 - val_loss: 0.5079 - val_accuracy: 0.7642\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7923 - val_loss: 0.5077 - val_accuracy: 0.7724\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7923 - val_loss: 0.5089 - val_accuracy: 0.7724\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7724\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7724\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7902 - val_loss: 0.5083 - val_accuracy: 0.7642\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7902 - val_loss: 0.5099 - val_accuracy: 0.7642\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7902 - val_loss: 0.5086 - val_accuracy: 0.7724\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7841 - val_loss: 0.5079 - val_accuracy: 0.7642\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7902 - val_loss: 0.5077 - val_accuracy: 0.7724\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7902 - val_loss: 0.5074 - val_accuracy: 0.7724\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7902 - val_loss: 0.5082 - val_accuracy: 0.7724\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7923 - val_loss: 0.5086 - val_accuracy: 0.7724\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7862 - val_loss: 0.5079 - val_accuracy: 0.7642\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7902 - val_loss: 0.5085 - val_accuracy: 0.7724\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7902 - val_loss: 0.5089 - val_accuracy: 0.7724\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7642\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7902 - val_loss: 0.5078 - val_accuracy: 0.7724\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7902 - val_loss: 0.5074 - val_accuracy: 0.7724\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7862 - val_loss: 0.5076 - val_accuracy: 0.7805\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7724\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7902 - val_loss: 0.5077 - val_accuracy: 0.7724\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7923 - val_loss: 0.5082 - val_accuracy: 0.7724\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7923 - val_loss: 0.5080 - val_accuracy: 0.7642\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7923 - val_loss: 0.5096 - val_accuracy: 0.7642\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7724\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7923 - val_loss: 0.5085 - val_accuracy: 0.7724\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7724\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7841 - val_loss: 0.5081 - val_accuracy: 0.7724\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7862 - val_loss: 0.5082 - val_accuracy: 0.7724\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7902 - val_loss: 0.5078 - val_accuracy: 0.7724\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7724\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7724\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7841 - val_loss: 0.5080 - val_accuracy: 0.7724\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7862 - val_loss: 0.5076 - val_accuracy: 0.7724\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7943 - val_loss: 0.5079 - val_accuracy: 0.7724\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7923 - val_loss: 0.5088 - val_accuracy: 0.7724\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7923 - val_loss: 0.5085 - val_accuracy: 0.7724\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7821 - val_loss: 0.5084 - val_accuracy: 0.7724\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7800 - val_loss: 0.5074 - val_accuracy: 0.7724\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7862 - val_loss: 0.5076 - val_accuracy: 0.7805\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7862 - val_loss: 0.5081 - val_accuracy: 0.7724\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7902 - val_loss: 0.5087 - val_accuracy: 0.7724\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7902 - val_loss: 0.5091 - val_accuracy: 0.7642\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7943 - val_loss: 0.5100 - val_accuracy: 0.7642\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7862 - val_loss: 0.5077 - val_accuracy: 0.7724\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7943 - val_loss: 0.5078 - val_accuracy: 0.7805\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7923 - val_loss: 0.5080 - val_accuracy: 0.7724\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7724\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7862 - val_loss: 0.5081 - val_accuracy: 0.7724\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7862 - val_loss: 0.5078 - val_accuracy: 0.7805\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7923 - val_loss: 0.5091 - val_accuracy: 0.7642\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7902 - val_loss: 0.5073 - val_accuracy: 0.7724\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7902 - val_loss: 0.5077 - val_accuracy: 0.7724\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7805\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7902 - val_loss: 0.5072 - val_accuracy: 0.7724\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7923 - val_loss: 0.5074 - val_accuracy: 0.7724\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7963 - val_loss: 0.5086 - val_accuracy: 0.7724\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7923 - val_loss: 0.5088 - val_accuracy: 0.7724\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7862 - val_loss: 0.5079 - val_accuracy: 0.7805\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7902 - val_loss: 0.5082 - val_accuracy: 0.7724\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7724\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7902 - val_loss: 0.5073 - val_accuracy: 0.7724\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7923 - val_loss: 0.5097 - val_accuracy: 0.7642\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7841 - val_loss: 0.5092 - val_accuracy: 0.7642\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7923 - val_loss: 0.5080 - val_accuracy: 0.7805\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7923 - val_loss: 0.5084 - val_accuracy: 0.7724\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7923 - val_loss: 0.5094 - val_accuracy: 0.7642\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7882 - val_loss: 0.5089 - val_accuracy: 0.7724\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7862 - val_loss: 0.5074 - val_accuracy: 0.7724\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7943 - val_loss: 0.5088 - val_accuracy: 0.7724\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7902 - val_loss: 0.5080 - val_accuracy: 0.7805\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7902 - val_loss: 0.5084 - val_accuracy: 0.7724\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7862 - val_loss: 0.5085 - val_accuracy: 0.7724\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7805\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7902 - val_loss: 0.5072 - val_accuracy: 0.7805\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7963 - val_loss: 0.5094 - val_accuracy: 0.7642\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7841 - val_loss: 0.5080 - val_accuracy: 0.7724\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7642\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7805\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7642\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7805\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7902 - val_loss: 0.5087 - val_accuracy: 0.7724\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7902 - val_loss: 0.5089 - val_accuracy: 0.7642\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7841 - val_loss: 0.5073 - val_accuracy: 0.7724\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7902 - val_loss: 0.5082 - val_accuracy: 0.7724\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7805\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7862 - val_loss: 0.5081 - val_accuracy: 0.7805\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7923 - val_loss: 0.5071 - val_accuracy: 0.7724\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7943 - val_loss: 0.5078 - val_accuracy: 0.7805\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7923 - val_loss: 0.5074 - val_accuracy: 0.7724\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7882 - val_loss: 0.5069 - val_accuracy: 0.7724\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7902 - val_loss: 0.5078 - val_accuracy: 0.7805\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7963 - val_loss: 0.5083 - val_accuracy: 0.7724\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7862 - val_loss: 0.5082 - val_accuracy: 0.7724\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7923 - val_loss: 0.5087 - val_accuracy: 0.7724\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7862 - val_loss: 0.5080 - val_accuracy: 0.7724\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7724\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7902 - val_loss: 0.5082 - val_accuracy: 0.7724\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7902 - val_loss: 0.5075 - val_accuracy: 0.7724\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7923 - val_loss: 0.5083 - val_accuracy: 0.7724\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7902 - val_loss: 0.5075 - val_accuracy: 0.7724\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7923 - val_loss: 0.5076 - val_accuracy: 0.7724\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7724\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7902 - val_loss: 0.5073 - val_accuracy: 0.7724\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7902 - val_loss: 0.5084 - val_accuracy: 0.7805\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7862 - val_loss: 0.5074 - val_accuracy: 0.7642\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7963 - val_loss: 0.5077 - val_accuracy: 0.7724\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7923 - val_loss: 0.5074 - val_accuracy: 0.7642\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7943 - val_loss: 0.5075 - val_accuracy: 0.7724\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7943 - val_loss: 0.5096 - val_accuracy: 0.7642\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7902 - val_loss: 0.5086 - val_accuracy: 0.7724\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7724\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7943 - val_loss: 0.5078 - val_accuracy: 0.7724\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7923 - val_loss: 0.5081 - val_accuracy: 0.7805\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7821 - val_loss: 0.5080 - val_accuracy: 0.7724\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7862 - val_loss: 0.5082 - val_accuracy: 0.7805\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7923 - val_loss: 0.5081 - val_accuracy: 0.7805\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7943 - val_loss: 0.5075 - val_accuracy: 0.7724\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7984 - val_loss: 0.5083 - val_accuracy: 0.7805\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7923 - val_loss: 0.5087 - val_accuracy: 0.7724\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7943 - val_loss: 0.5103 - val_accuracy: 0.7642\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7724\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7943 - val_loss: 0.5089 - val_accuracy: 0.7724\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7902 - val_loss: 0.5076 - val_accuracy: 0.7724\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7902 - val_loss: 0.5103 - val_accuracy: 0.7642\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7923 - val_loss: 0.5098 - val_accuracy: 0.7642\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7882 - val_loss: 0.5094 - val_accuracy: 0.7642\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7943 - val_loss: 0.5096 - val_accuracy: 0.7642\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7724\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7923 - val_loss: 0.5077 - val_accuracy: 0.7724\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7923 - val_loss: 0.5082 - val_accuracy: 0.7805\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7943 - val_loss: 0.5080 - val_accuracy: 0.7724\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7963 - val_loss: 0.5087 - val_accuracy: 0.7724\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7862 - val_loss: 0.5077 - val_accuracy: 0.7724\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7902 - val_loss: 0.5075 - val_accuracy: 0.7724\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7923 - val_loss: 0.5080 - val_accuracy: 0.7724\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7724\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7862 - val_loss: 0.5086 - val_accuracy: 0.7724\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7923 - val_loss: 0.5101 - val_accuracy: 0.7642\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7841 - val_loss: 0.5089 - val_accuracy: 0.7724\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7902 - val_loss: 0.5084 - val_accuracy: 0.7805\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7902 - val_loss: 0.5082 - val_accuracy: 0.7724\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7561\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7943 - val_loss: 0.5086 - val_accuracy: 0.7805\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5097 - val_accuracy: 0.7642\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7724\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7902 - val_loss: 0.5111 - val_accuracy: 0.7642\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7902 - val_loss: 0.5122 - val_accuracy: 0.7642\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5090 - val_accuracy: 0.7724\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7902 - val_loss: 0.5079 - val_accuracy: 0.7724\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7724\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7724\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7943 - val_loss: 0.5106 - val_accuracy: 0.7642\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7862 - val_loss: 0.5089 - val_accuracy: 0.7724\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7841 - val_loss: 0.5079 - val_accuracy: 0.7724\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7943 - val_loss: 0.5078 - val_accuracy: 0.7642\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7923 - val_loss: 0.5083 - val_accuracy: 0.7724\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7902 - val_loss: 0.5094 - val_accuracy: 0.7642\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7943 - val_loss: 0.5102 - val_accuracy: 0.7642\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7480\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7943 - val_loss: 0.5083 - val_accuracy: 0.7642\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7943 - val_loss: 0.5097 - val_accuracy: 0.7642\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7561\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7902 - val_loss: 0.5091 - val_accuracy: 0.7724\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7642\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7963 - val_loss: 0.5079 - val_accuracy: 0.7642\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7923 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7943 - val_loss: 0.5076 - val_accuracy: 0.7480\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7943 - val_loss: 0.5093 - val_accuracy: 0.7724\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7902 - val_loss: 0.5079 - val_accuracy: 0.7642\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7923 - val_loss: 0.5081 - val_accuracy: 0.7724\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7923 - val_loss: 0.5076 - val_accuracy: 0.7561\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7923 - val_loss: 0.5100 - val_accuracy: 0.7642\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7642\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7902 - val_loss: 0.5087 - val_accuracy: 0.7805\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7943 - val_loss: 0.5082 - val_accuracy: 0.7724\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7923 - val_loss: 0.5094 - val_accuracy: 0.7642\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7923 - val_loss: 0.5081 - val_accuracy: 0.7724\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7943 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7902 - val_loss: 0.5078 - val_accuracy: 0.7724\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7943 - val_loss: 0.5081 - val_accuracy: 0.7724\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7943 - val_loss: 0.5080 - val_accuracy: 0.7724\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7963 - val_loss: 0.5087 - val_accuracy: 0.7805\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7642\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7724\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7902 - val_loss: 0.5091 - val_accuracy: 0.7724\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7902 - val_loss: 0.5083 - val_accuracy: 0.7724\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7902 - val_loss: 0.5100 - val_accuracy: 0.7642\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7642\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7902 - val_loss: 0.5093 - val_accuracy: 0.7642\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7943 - val_loss: 0.5081 - val_accuracy: 0.7724\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7923 - val_loss: 0.5082 - val_accuracy: 0.7724\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7923 - val_loss: 0.5087 - val_accuracy: 0.7805\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7943 - val_loss: 0.5083 - val_accuracy: 0.7724\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7862 - val_loss: 0.5078 - val_accuracy: 0.7724\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7902 - val_loss: 0.5077 - val_accuracy: 0.7724\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7923 - val_loss: 0.5076 - val_accuracy: 0.7561\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7862 - val_loss: 0.5079 - val_accuracy: 0.7642\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7923 - val_loss: 0.5093 - val_accuracy: 0.7642\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7984 - val_loss: 0.5076 - val_accuracy: 0.7561\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7943 - val_loss: 0.5088 - val_accuracy: 0.7724\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7561\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7923 - val_loss: 0.5079 - val_accuracy: 0.7724\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7984 - val_loss: 0.5080 - val_accuracy: 0.7724\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7862 - val_loss: 0.5081 - val_accuracy: 0.7724\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7862 - val_loss: 0.5075 - val_accuracy: 0.7561\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4365 - accuracy: 0.7902 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7963 - val_loss: 0.5080 - val_accuracy: 0.7724\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7902 - val_loss: 0.5085 - val_accuracy: 0.7805\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7923 - val_loss: 0.5092 - val_accuracy: 0.7642\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7902 - val_loss: 0.5095 - val_accuracy: 0.7642\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7841 - val_loss: 0.5074 - val_accuracy: 0.7642\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7902 - val_loss: 0.5075 - val_accuracy: 0.7561\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7821 - val_loss: 0.5074 - val_accuracy: 0.7480\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7882 - val_loss: 0.5081 - val_accuracy: 0.7724\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7841 - val_loss: 0.5079 - val_accuracy: 0.7642\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7923 - val_loss: 0.5088 - val_accuracy: 0.7642\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7943 - val_loss: 0.5073 - val_accuracy: 0.7561\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7923 - val_loss: 0.5073 - val_accuracy: 0.7480\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7561\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7642\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.5089 - val_accuracy: 0.7642\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7902 - val_loss: 0.5096 - val_accuracy: 0.7642\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7923 - val_loss: 0.5103 - val_accuracy: 0.7642\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7984 - val_loss: 0.5088 - val_accuracy: 0.7642\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7963 - val_loss: 0.5081 - val_accuracy: 0.7724\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7642\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7902 - val_loss: 0.5076 - val_accuracy: 0.7642\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7943 - val_loss: 0.5087 - val_accuracy: 0.7724\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7724\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7943 - val_loss: 0.5095 - val_accuracy: 0.7642\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7923 - val_loss: 0.5075 - val_accuracy: 0.7561\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7923 - val_loss: 0.5075 - val_accuracy: 0.7561\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.5089 - val_accuracy: 0.7642\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7902 - val_loss: 0.5075 - val_accuracy: 0.7480\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7943 - val_loss: 0.5078 - val_accuracy: 0.7642\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7902 - val_loss: 0.5073 - val_accuracy: 0.7561\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7923 - val_loss: 0.5075 - val_accuracy: 0.7561\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7923 - val_loss: 0.5093 - val_accuracy: 0.7642\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7902 - val_loss: 0.5071 - val_accuracy: 0.7561\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7902 - val_loss: 0.5071 - val_accuracy: 0.7561\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7923 - val_loss: 0.5086 - val_accuracy: 0.7642\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7923 - val_loss: 0.5071 - val_accuracy: 0.7642\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7943 - val_loss: 0.5070 - val_accuracy: 0.7642\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7943 - val_loss: 0.5078 - val_accuracy: 0.7642\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7923 - val_loss: 0.5070 - val_accuracy: 0.7561\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7984 - val_loss: 0.5068 - val_accuracy: 0.7724\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7943 - val_loss: 0.5067 - val_accuracy: 0.7642\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7923 - val_loss: 0.5074 - val_accuracy: 0.7642\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7642\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7963 - val_loss: 0.5082 - val_accuracy: 0.7642\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7943 - val_loss: 0.5088 - val_accuracy: 0.7642\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.7923 - val_loss: 0.5074 - val_accuracy: 0.7642\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7923 - val_loss: 0.5081 - val_accuracy: 0.7724\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7902 - val_loss: 0.5075 - val_accuracy: 0.7642\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7923 - val_loss: 0.5069 - val_accuracy: 0.7642\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7943 - val_loss: 0.5070 - val_accuracy: 0.7642\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7862 - val_loss: 0.5093 - val_accuracy: 0.7642\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7902 - val_loss: 0.5073 - val_accuracy: 0.7642\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7923 - val_loss: 0.5080 - val_accuracy: 0.7724\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7943 - val_loss: 0.5095 - val_accuracy: 0.7642\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7902 - val_loss: 0.5071 - val_accuracy: 0.7642\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7902 - val_loss: 0.5075 - val_accuracy: 0.7642\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7963 - val_loss: 0.5079 - val_accuracy: 0.7642\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7923 - val_loss: 0.5078 - val_accuracy: 0.7724\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7923 - val_loss: 0.5071 - val_accuracy: 0.7642\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7943 - val_loss: 0.5074 - val_accuracy: 0.7642\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7902 - val_loss: 0.5074 - val_accuracy: 0.7642\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7943 - val_loss: 0.5074 - val_accuracy: 0.7642\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7862 - val_loss: 0.5069 - val_accuracy: 0.7642\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7923 - val_loss: 0.5085 - val_accuracy: 0.7642\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7943 - val_loss: 0.5076 - val_accuracy: 0.7724\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7882 - val_loss: 0.5065 - val_accuracy: 0.7642\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7882 - val_loss: 0.5065 - val_accuracy: 0.7642\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7882 - val_loss: 0.5061 - val_accuracy: 0.7561\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7902 - val_loss: 0.5063 - val_accuracy: 0.7642\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7882 - val_loss: 0.5066 - val_accuracy: 0.7642\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7902 - val_loss: 0.5059 - val_accuracy: 0.7642\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7923 - val_loss: 0.5066 - val_accuracy: 0.7642\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7943 - val_loss: 0.5090 - val_accuracy: 0.7642\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7862 - val_loss: 0.5061 - val_accuracy: 0.7642\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7943 - val_loss: 0.5059 - val_accuracy: 0.7724\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7862 - val_loss: 0.5081 - val_accuracy: 0.7561\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7943 - val_loss: 0.5069 - val_accuracy: 0.7642\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7943 - val_loss: 0.5061 - val_accuracy: 0.7642\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7923 - val_loss: 0.5067 - val_accuracy: 0.7642\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7963 - val_loss: 0.5060 - val_accuracy: 0.7642\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7963 - val_loss: 0.5059 - val_accuracy: 0.7642\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7963 - val_loss: 0.5055 - val_accuracy: 0.7642\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7923 - val_loss: 0.5059 - val_accuracy: 0.7642\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7963 - val_loss: 0.5075 - val_accuracy: 0.7561\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7724\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7882 - val_loss: 0.5065 - val_accuracy: 0.7642\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7923 - val_loss: 0.5059 - val_accuracy: 0.7642\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7963 - val_loss: 0.5071 - val_accuracy: 0.7724\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7923 - val_loss: 0.5077 - val_accuracy: 0.7561\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7943 - val_loss: 0.5069 - val_accuracy: 0.7724\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7862 - val_loss: 0.5078 - val_accuracy: 0.7561\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7923 - val_loss: 0.5084 - val_accuracy: 0.7642\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7902 - val_loss: 0.5076 - val_accuracy: 0.7561\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7963 - val_loss: 0.5081 - val_accuracy: 0.7561\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7902 - val_loss: 0.5060 - val_accuracy: 0.7642\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7902 - val_loss: 0.5059 - val_accuracy: 0.7642\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7862 - val_loss: 0.5071 - val_accuracy: 0.7724\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7923 - val_loss: 0.5054 - val_accuracy: 0.7724\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7724\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7923 - val_loss: 0.5058 - val_accuracy: 0.7642\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7862 - val_loss: 0.5062 - val_accuracy: 0.7642\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7963 - val_loss: 0.5068 - val_accuracy: 0.7724\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7862 - val_loss: 0.5065 - val_accuracy: 0.7724\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7923 - val_loss: 0.5057 - val_accuracy: 0.7642\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7902 - val_loss: 0.5067 - val_accuracy: 0.7724\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7902 - val_loss: 0.5058 - val_accuracy: 0.7642\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7923 - val_loss: 0.5057 - val_accuracy: 0.7642\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7923 - val_loss: 0.5058 - val_accuracy: 0.7642\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7902 - val_loss: 0.5048 - val_accuracy: 0.7642\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7882 - val_loss: 0.5043 - val_accuracy: 0.7724\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7902 - val_loss: 0.5041 - val_accuracy: 0.7724\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7882 - val_loss: 0.5048 - val_accuracy: 0.7642\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7923 - val_loss: 0.5046 - val_accuracy: 0.7642\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7923 - val_loss: 0.5051 - val_accuracy: 0.7642\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7923 - val_loss: 0.5036 - val_accuracy: 0.7724\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7943 - val_loss: 0.5036 - val_accuracy: 0.7642\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7862 - val_loss: 0.5030 - val_accuracy: 0.7724\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7923 - val_loss: 0.5032 - val_accuracy: 0.7642\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7902 - val_loss: 0.5027 - val_accuracy: 0.7724\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7902 - val_loss: 0.5023 - val_accuracy: 0.7805\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7963 - val_loss: 0.5025 - val_accuracy: 0.7642\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7943 - val_loss: 0.5026 - val_accuracy: 0.7642\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7943 - val_loss: 0.5036 - val_accuracy: 0.7724\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7902 - val_loss: 0.5021 - val_accuracy: 0.7724\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7882 - val_loss: 0.5019 - val_accuracy: 0.7724\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7943 - val_loss: 0.5027 - val_accuracy: 0.7724\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7923 - val_loss: 0.5035 - val_accuracy: 0.7805\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7902 - val_loss: 0.5022 - val_accuracy: 0.7642\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7963 - val_loss: 0.5033 - val_accuracy: 0.7805\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7902 - val_loss: 0.5033 - val_accuracy: 0.7805\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7724\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7886\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7984 - val_loss: 0.5014 - val_accuracy: 0.7642\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7923 - val_loss: 0.5011 - val_accuracy: 0.7805\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7963 - val_loss: 0.5013 - val_accuracy: 0.7724\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7923 - val_loss: 0.5018 - val_accuracy: 0.7642\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7902 - val_loss: 0.5012 - val_accuracy: 0.7642\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7923 - val_loss: 0.5012 - val_accuracy: 0.7724\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7943 - val_loss: 0.5014 - val_accuracy: 0.7724\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7902 - val_loss: 0.5009 - val_accuracy: 0.7805\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7902 - val_loss: 0.5013 - val_accuracy: 0.7642\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7984 - val_loss: 0.5012 - val_accuracy: 0.7642\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7923 - val_loss: 0.5022 - val_accuracy: 0.7724\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7642\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7724\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7902 - val_loss: 0.5009 - val_accuracy: 0.7805\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7902 - val_loss: 0.5009 - val_accuracy: 0.7805\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7862 - val_loss: 0.5009 - val_accuracy: 0.7805\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7902 - val_loss: 0.5009 - val_accuracy: 0.7805\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7923 - val_loss: 0.5013 - val_accuracy: 0.7642\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7902 - val_loss: 0.5008 - val_accuracy: 0.7805\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7902 - val_loss: 0.5007 - val_accuracy: 0.7805\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7862 - val_loss: 0.5013 - val_accuracy: 0.7642\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7923 - val_loss: 0.5007 - val_accuracy: 0.7805\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7642\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7923 - val_loss: 0.5011 - val_accuracy: 0.7561\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7902 - val_loss: 0.5006 - val_accuracy: 0.7805\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7902 - val_loss: 0.5014 - val_accuracy: 0.7642\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7902 - val_loss: 0.5012 - val_accuracy: 0.7642\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7923 - val_loss: 0.5008 - val_accuracy: 0.7561\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7841 - val_loss: 0.5010 - val_accuracy: 0.7642\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7902 - val_loss: 0.5014 - val_accuracy: 0.7642\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7862 - val_loss: 0.5003 - val_accuracy: 0.7805\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7923 - val_loss: 0.5002 - val_accuracy: 0.7805\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7841 - val_loss: 0.5012 - val_accuracy: 0.7642\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7642\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7902 - val_loss: 0.5003 - val_accuracy: 0.7642\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.4999 - val_accuracy: 0.7805\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7902 - val_loss: 0.5008 - val_accuracy: 0.7642\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7963 - val_loss: 0.5006 - val_accuracy: 0.7724\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7805\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7724\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7984 - val_loss: 0.4998 - val_accuracy: 0.7724\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7902 - val_loss: 0.5004 - val_accuracy: 0.7724\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7724\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7862 - val_loss: 0.4994 - val_accuracy: 0.7805\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7923 - val_loss: 0.4998 - val_accuracy: 0.7724\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7821 - val_loss: 0.5004 - val_accuracy: 0.7642\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7923 - val_loss: 0.4988 - val_accuracy: 0.7805\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7943 - val_loss: 0.4987 - val_accuracy: 0.7805\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7963 - val_loss: 0.4997 - val_accuracy: 0.7724\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7963 - val_loss: 0.5000 - val_accuracy: 0.7724\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7862 - val_loss: 0.4987 - val_accuracy: 0.7805\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7882 - val_loss: 0.4986 - val_accuracy: 0.7805\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7963 - val_loss: 0.5000 - val_accuracy: 0.7642\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7841 - val_loss: 0.4991 - val_accuracy: 0.7724\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7821 - val_loss: 0.4988 - val_accuracy: 0.7805\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7882 - val_loss: 0.4987 - val_accuracy: 0.7805\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7943 - val_loss: 0.5010 - val_accuracy: 0.7642\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7902 - val_loss: 0.4987 - val_accuracy: 0.7805\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7841 - val_loss: 0.4987 - val_accuracy: 0.7805\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7862 - val_loss: 0.4987 - val_accuracy: 0.7805\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.4985 - val_accuracy: 0.7805\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7943 - val_loss: 0.4988 - val_accuracy: 0.7724\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7902 - val_loss: 0.4990 - val_accuracy: 0.7724\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7923 - val_loss: 0.5007 - val_accuracy: 0.7724\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7821 - val_loss: 0.4988 - val_accuracy: 0.7805\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.4986 - val_accuracy: 0.7805\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7923 - val_loss: 0.4987 - val_accuracy: 0.7805\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7642\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7642\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7821 - val_loss: 0.4987 - val_accuracy: 0.7805\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.4987 - val_accuracy: 0.7724\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7923 - val_loss: 0.4987 - val_accuracy: 0.7724\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7902 - val_loss: 0.4995 - val_accuracy: 0.7642\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.4988 - val_accuracy: 0.7805\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7642\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7902 - val_loss: 0.5005 - val_accuracy: 0.7642\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7642\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7862 - val_loss: 0.5002 - val_accuracy: 0.7642\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7862 - val_loss: 0.4990 - val_accuracy: 0.7805\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7902 - val_loss: 0.4991 - val_accuracy: 0.7805\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.4990 - val_accuracy: 0.7724\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7963 - val_loss: 0.4991 - val_accuracy: 0.7805\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.4991 - val_accuracy: 0.7805\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7923 - val_loss: 0.4993 - val_accuracy: 0.7805\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7862 - val_loss: 0.4990 - val_accuracy: 0.7805\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7943 - val_loss: 0.4994 - val_accuracy: 0.7724\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.4991 - val_accuracy: 0.7724\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.4992 - val_accuracy: 0.7805\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7943 - val_loss: 0.4992 - val_accuracy: 0.7805\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7862 - val_loss: 0.4994 - val_accuracy: 0.7724\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7902 - val_loss: 0.4998 - val_accuracy: 0.7642\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.4999 - val_accuracy: 0.7642\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7841 - val_loss: 0.4996 - val_accuracy: 0.7724\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7902 - val_loss: 0.4993 - val_accuracy: 0.7805\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7902 - val_loss: 0.4998 - val_accuracy: 0.7642\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7724\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7724\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7805\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7724\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7862 - val_loss: 0.4996 - val_accuracy: 0.7805\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7923 - val_loss: 0.4996 - val_accuracy: 0.7805\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7902 - val_loss: 0.4996 - val_accuracy: 0.7805\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7984 - val_loss: 0.5002 - val_accuracy: 0.7642\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7902 - val_loss: 0.4996 - val_accuracy: 0.7805\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7923 - val_loss: 0.4998 - val_accuracy: 0.7805\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7862 - val_loss: 0.4998 - val_accuracy: 0.7724\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7724\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7902 - val_loss: 0.5003 - val_accuracy: 0.7724\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.4999 - val_accuracy: 0.7805\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7923 - val_loss: 0.5001 - val_accuracy: 0.7642\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7902 - val_loss: 0.5001 - val_accuracy: 0.7724\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7943 - val_loss: 0.5017 - val_accuracy: 0.7642\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7841 - val_loss: 0.5001 - val_accuracy: 0.7805\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7805\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL5jgZT8IWIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "f5b3fcba-2840-4982-d3b4-321924c5dec9"
      },
      "source": [
        "# Visualize the training loss and the validation loss to see if the model has overfit\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc = 'upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6Jgi9JhJna6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "7d5cecef-67c8-4843-dc1c-41236c0f9bde"
      },
      "source": [
        "# Visualize the training accuracy and the validation accuracy\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc = 'lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGnv0hg_KLqi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "746453f7-dea8-4e49-c8b9-3206537c2658"
      },
      "source": [
        "# Make a prediction and print the actual values\n",
        "prediction = model.predict(X_test)\n",
        "prediction = [1 if y>=0.5 else 0 for y in prediction] \n",
        "print(prediction)\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1]\n",
            "[0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be_VcFCPKoYB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "b83ac5c0-c1f1-4c60-f899-e8a70d278a87"
      },
      "source": [
        "# Evaluate the model on the training data \n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "pred = model.predict(X_train)\n",
        "pred = [1 if y>=0.5 else 0 for y in pred]\n",
        "print(classification_report(y_train, pred))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_train, pred))\n",
        "print()\n",
        "print('Accuracy: ', accuracy_score(y_train, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.81      0.88      0.85       398\n",
            "         1.0       0.75      0.62      0.68       216\n",
            "\n",
            "    accuracy                           0.79       614\n",
            "   macro avg       0.78      0.75      0.76       614\n",
            "weighted avg       0.79      0.79      0.79       614\n",
            "\n",
            "Confusion Matrix: \n",
            " [[352  46]\n",
            " [ 81 135]]\n",
            "\n",
            "Accuracy:  0.7931596091205212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj2wQJQwMIyT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "5ce7cd0b-ecad-4263-f7bf-fa6f38b40cd5"
      },
      "source": [
        "# Evaluate the model on the testing data \n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "pred = model.predict(X_test)\n",
        "pred = [1 if y>=0.5 else 0 for y in pred]\n",
        "print(classification_report(y_test, pred))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, pred))\n",
        "print()\n",
        "print('Accuracy: ', accuracy_score(y_test, pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.82      0.82       102\n",
            "         1.0       0.65      0.65      0.65        52\n",
            "\n",
            "    accuracy                           0.77       154\n",
            "   macro avg       0.74      0.74      0.74       154\n",
            "weighted avg       0.77      0.77      0.77       154\n",
            "\n",
            "Confusion Matrix: \n",
            " [[84 18]\n",
            " [18 34]]\n",
            "\n",
            "Accuracy:  0.7662337662337663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4qrPsP3N5uf",
        "colab_type": "text"
      },
      "source": [
        "### The model performed decent; however, further manipulation of the data could result in higher accuracy, which is always best to strive for, especially when dealing with human life and the medical field in general."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reJzOgO9NnfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}